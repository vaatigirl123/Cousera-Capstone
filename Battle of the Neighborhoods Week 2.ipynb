{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "# Introduction"}, {"metadata": {}, "cell_type": "markdown", "source": "In this project we will help people who are looking for renting an apartment in Vienna. If they are looking to move to Vienna they can see:"}, {"metadata": {}, "cell_type": "markdown", "source": "1. Which district has cheaper rent or,\n2. They can choose to live in residential or commercial areas and can see for example which residential districts is best"}, {"metadata": {}, "cell_type": "markdown", "source": "Or, if they already live in one of the 23 districts in Vienna they will be able to see:"}, {"metadata": {}, "cell_type": "markdown", "source": "1. If they are paying more than the average price for their apartment\n2. If there are similar districts to theirs with lower rents"}, {"metadata": {}, "cell_type": "markdown", "source": "# Data"}, {"metadata": {}, "cell_type": "markdown", "source": "The data on apartments (size, number of rooms, address, and price) is collected by scraping a local website with apartment listings (willhaben.at). Using geopy we find the coordinates for each district and then using Foursquare we collect the closest venues (supermarket, restaurant, park, etc.). After the data collection we can run k-means clustering to cluster the districts into residential and commercial areas and visualize all the data on a single choropleth map."}, {"metadata": {}, "cell_type": "markdown", "source": "# Load dependencies"}, {"metadata": {}, "cell_type": "code", "source": "!pip install beautifulsoup4\n!pip install lxml\nimport requests # library to handle requests\nimport pandas as pd # library for data analsysis\nimport numpy as np # library to handle data in a vectorized manner\nimport random # library for random number generation\n\n#!conda install -c conda-forge geopy --yes \nfrom geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\n\n# libraries for displaying images\nfrom IPython.display import Image \nfrom IPython.core.display import HTML \n\n\nfrom IPython.display import display_html\nimport pandas as pd\nimport numpy as np\n    \n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\n\n!conda install -c conda-forge folium=0.5.0 --yes\nimport folium # plotting library\nfrom bs4 import BeautifulSoup\nfrom sklearn.cluster import KMeans\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\nprint('Folium installed')\nprint('Libraries imported.')", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: beautifulsoup4 in /opt/conda/envs/Python36/lib/python3.6/site-packages (4.7.1)\nRequirement already satisfied: soupsieve>=1.2 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from beautifulsoup4) (1.7.1)\nRequirement already satisfied: lxml in /opt/conda/envs/Python36/lib/python3.6/site-packages (4.3.1)\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda/envs/Python36\n\n  added / updated specs: \n    - folium=0.5.0\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    openssl-1.1.1g             |       h516909a_0         2.1 MB  conda-forge\n    python_abi-3.6             |          1_cp36m           4 KB  conda-forge\n    ca-certificates-2020.4.5.1 |       hecc5488_0         146 KB  conda-forge\n    altair-4.1.0               |             py_1         614 KB  conda-forge\n    vincent-0.4.4              |             py_1          28 KB  conda-forge\n    folium-0.5.0               |             py_0          45 KB  conda-forge\n    branca-0.4.1               |             py_0          26 KB  conda-forge\n    certifi-2020.4.5.1         |   py36h9f0ad1d_0         151 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         3.1 MB\n\nThe following NEW packages will be INSTALLED:\n\n    altair:          4.1.0-py_1        conda-forge\n    branca:          0.4.1-py_0        conda-forge\n    folium:          0.5.0-py_0        conda-forge\n    python_abi:      3.6-1_cp36m       conda-forge\n    vincent:         0.4.4-py_1        conda-forge\n\nThe following packages will be UPDATED:\n\n    ca-certificates: 2020.1.1-0                    --> 2020.4.5.1-hecc5488_0     conda-forge\n    certifi:         2020.4.5.1-py36_0             --> 2020.4.5.1-py36h9f0ad1d_0 conda-forge\n    openssl:         1.1.1g-h7b6447c_0             --> 1.1.1g-h516909a_0         conda-forge\n\n\nDownloading and Extracting Packages\nopenssl-1.1.1g       | 2.1 MB    | ##################################### | 100% \npython_abi-3.6       | 4 KB      | ##################################### | 100% \nca-certificates-2020 | 146 KB    | ##################################### | 100% \naltair-4.1.0         | 614 KB    | ##################################### | 100% \nvincent-0.4.4        | 28 KB     | ##################################### | 100% \nfolium-0.5.0         | 45 KB     | ##################################### | 100% \nbranca-0.4.1         | 26 KB     | ##################################### | 100% \ncertifi-2020.4.5.1   | 151 KB    | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\nFolium installed\nLibraries imported.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "listing_found = True\npage_num = 1\nlistings = []\n\nwhile listing_found:\n    \n    # define header to make the request look like it's comming from an actual browser\n    headers = {'User-agent': 'Googlebot'}\n    \n    # set url \n    url = 'https://www.willhaben.at/iad/immobilien/mietwohnungen/mietwohnung-angebote?areaId=900&page={}&rows=200'.format(page_num)\n    \n    # load the response\n    response = get(url, headers=headers)\n    soup = BeautifulSoup(response.text, 'html.parser')\n    \n    # find all outer containers of listings\n    apartment_containers = soup.find_all('section', class_=\"content-section isRealestate\")\n    \n    # check if page contains listings\n    if len(apartment_containers) == 0:\n        break\n    \n    # for each apartment extract relevant data\n    for apt in apartment_containers:\n        try:\n            info = apt.find_all('div', class_=\"info\")[0]\n\n            try:\n                size = info.find_all('span', class_=\"desc-left\")[0].text.split()[0]\n            except:\n                size = np.nan\n\n            try:\n                rooms = info.find_all('span', class_=\"desc-left\")[0].text.split()[2]\n            except:\n                rooms = np.nan\n\n            try:\n                price = info.find_all('span', class_=\"pull-right\")[0].text.split()[0]\n            except:\n                price = np.nan\n\n        except:\n            size, rooms, price = np.nan\n\n        try:\n            full_address = apt.find_all('div', class_=\"address-lg w-brk-ln-1\")[0].text.split()\n            full_address = ' '.join(full_address)\n\n            postal_code = re.search('1\\d\\d0', full_address)[0]\n            district = full_address.split(', ')[-1]\n\n            if address == None:\n                address = None\n            else:\n                address = address[1]\n\n                if len(address.split(', ')) > 1:\n                    address = address.split(', ')[0]\n        except:\n            address = None\n            postal_code = None\n            district = None\n\n        listings.append([postal_code, district, size, rooms, price])\n    \n    # increase page number\n    page_num += 1\n    \n    # set sleep to mimic a more human behaviour and don't overload the site with requests\n    sleep(np.random.randint(1,3))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Set column names and build a dataframe from previous results"}, {"metadata": {}, "cell_type": "code", "source": "column_names = ['PostalCode', 'District', 'Size', 'Rooms', 'Price']\nrental_properties = pd.DataFrame(listings, columns=column_names)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('There are {} apartments in the dataset'.format(rental_properties.shape[0]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "rental_properties.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# 2. Pre-process & Visualize the data"}, {"metadata": {}, "cell_type": "markdown", "source": "### Adjust the data so they have the same format for each column"}, {"metadata": {}, "cell_type": "code", "source": "rental_properties['Size'] = rental_properties['Size'].str.replace('\u2013', 'NaN').astype('float')\nrental_properties['Rooms'] = rental_properties['Rooms'].astype('float')\nrental_properties['Price'] = rental_properties['Price'].str.replace('.', '').str.replace(',', '.').str.replace('-', '00').str.replace('vermietet', 'NaN').astype('float')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Calculate the price per meter squared"}, {"metadata": {}, "cell_type": "code", "source": "rental_properties['Price/m2'] = (rental_properties['Price']/rental_properties['Size']).round(2)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "rental_properties.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "rental_properties.describe()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "rental_properties.dtypes", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Remove rows with NA values in all columns except for the number of rooms since there are too many missing values"}, {"metadata": {}, "cell_type": "code", "source": "rental_properties.dropna(subset=['PostalCode', 'District', 'Size', 'Price'], inplace=True)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('There are {} apartments in the dataset'.format(rental_properties.shape[0]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Let's check how many apartments per room number we have in our dataset"}, {"metadata": {}, "cell_type": "code", "source": "rental_properties['Rooms'].value_counts()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Let's remove all rows with rooms larger than 6. Apartments bigger than 6 will most likely be luxurious apartments and does not fit the target group."}, {"metadata": {}, "cell_type": "code", "source": "rental_properties = rental_properties[rental_properties['Rooms'] <= 6]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### We can visualize the number of apartments per room number and number of apartments in each district"}, {"metadata": {}, "cell_type": "code", "source": "fig, ax =plt.subplots(2,1, figsize=(12,15))\nsns.countplot(rental_properties['Rooms'], ax=ax[0])\nsns.countplot(rental_properties['PostalCode'], ax=ax[1])\nax[1].set_xticklabels(ax[1].get_xticklabels(), rotation=50, ha=\"right\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Plot the price and check for any outliers"}, {"metadata": {}, "cell_type": "code", "source": "sns.jointplot(x='Size', y='Price', data=rental_properties[['Size','Price']])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Remove the outliers"}, {"metadata": {}, "cell_type": "code", "source": "rental_properties = rental_properties[rental_properties['Price'] <= 7000]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "sns.jointplot(x='Size', y='Price', data=rental_properties[['Size','Price']])\nOut[18]:\n<seaborn.axisgrid.JointGrid at 0x7fb9baefccc0>", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### We expect the value of properties to go up as the number of rooms increases. The interesting aspect in this boxplot is that 1 and 2 room apartments are competing in the same price range."}, {"metadata": {}, "cell_type": "code", "source": "sns.boxplot(x='Rooms', y='Price', data=rental_properties)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### In the following plot we can see that the price/m2 is in the same price range for all size apartments besides for single room apartments where the price/m2 goes even higher"}, {"metadata": {}, "cell_type": "code", "source": "sns.boxplot(x='Rooms', y='Price/m2', data=rental_properties)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Let's also check the differences in price per m2 in each district"}, {"metadata": {}, "cell_type": "code", "source": "plt.figure(figsize=(15,10))\nax = sns.boxplot(x='PostalCode', y='Price', data=rental_properties)\nax.set_xticklabels(ax.get_xticklabels(), rotation=50, ha=\"right\")\nax.tick_params(labelsize=13)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Save the dataframe to a csv file (optional)"}, {"metadata": {}, "cell_type": "code", "source": "# vienna_districts.to_csv('district_coordinates.csv', index=False)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# 3. Get coordinates for each district"}, {"metadata": {}, "cell_type": "markdown", "source": "### To avoid fetching coordinates for the same districts many times, we find the unique postal codes and find the coordinates once for each district"}, {"metadata": {}, "cell_type": "code", "source": "# vienna_districts = pd.read_csv('district_coordinates.csv')\n# vienna_districts", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "vienna_districts = rental_properties[['PostalCode','District']].drop_duplicates().sort_values(by=['PostalCode']).reset_index(drop=True)\nvienna_districts", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "latitude = np.zeros(vienna_districts.shape[0])\nlongitude = np.zeros(vienna_districts.shape[0])\n\ngeolocator = Nominatim(user_agent=\"vienna_explorer\")\n\nfor idx in range(vienna_districts.shape[0]):\n    address = vienna_districts['District'].loc[idx] + ', Wien'\n    \n    location = geolocator.geocode(address)\n    latitude[idx] = location.latitude\n    longitude[idx] = location.longitude", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "district_coordinates = vienna_districts\ndistrict_coordinates['Latitude'] = latitude\ndistrict_coordinates['Longitude'] = longitude\ndistrict_coordinates", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### We can visualize the districts on a map"}, {"metadata": {}, "cell_type": "code", "source": "# create map of Vienna using latitude and longitude values\nmap_vienna = folium.Map(location=[48.2012167,16.3725062], zoom_start=12)\n\n# add markers to map\nfor lat, lng, postalcode, district in zip(district_coordinates['Latitude'], district_coordinates['Longitude'], district_coordinates['PostalCode'], district_coordinates['District']):\n    dist = postalcode[1:3]\n    label = '{}. {}'.format(dist, district)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_vienna)  \n    \nmap_vienna", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# 4. Visualize the average price/m2 & average apartment size per district on a choropleth map"}, {"metadata": {}, "cell_type": "markdown", "source": "### Extract only the Vienna districts from the JSON file and edit the keys to match our data\n\nJSON file from: https://github.com/ginseng666/GeoJSON-TopoJSON-Austria"}, {"metadata": {}, "cell_type": "code", "source": "with open('gemeinden_wien_bezirke_geo.json') as json_data:\n    location_data = json.load(json_data)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "location_data['features'] = location_data['features'][:23]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "for idx in range(len(location_data['features'])):\n    location_data['features'][idx]['properties']['name'] = location_data['features'][idx]['properties']['name'].replace('Wien ','')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Calculate the mean per district"}, {"metadata": {}, "cell_type": "code", "source": "mean_per_district = rental_properties.groupby('District').mean().reset_index()\nmean_per_district.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# 4.1 Average price/m2 per district"}, {"metadata": {}, "cell_type": "code", "source": "# vienna_geo = r'BEZIRKSGRENZEOGD.json' # geojson file\nvienna_geo = location_data\n\n# create a plain map of Vienna\nvienna_map = folium.Map(location=[48.2012167,16.3725062], zoom_start=12)\n\n# add the data\nvienna_map.choropleth(\n    geo_data=location_data,\n    data=mean_per_district,\n    columns=['District', 'Price/m2'],\n    key_on='feature.properties.name',\n    fill_color='YlOrRd', \n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='Average price/m2 for each district in Vienna'\n)\n\n# add markers to map\nfor lat, lng, postalcode, district in zip(district_coordinates['Latitude'], district_coordinates['Longitude'], district_coordinates['PostalCode'], district_coordinates['District']):\n    dist = postalcode[1:3]\n    label = '{}. {}'.format(dist, district)\n    label = folium.Popup(label, parse_html=True)\n    folium.Circle(\n        [lat, lng],\n        radius=100,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(vienna_map) \n\n# display map\nvienna_map", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# 4.2 Average apartment size per district"}, {"metadata": {}, "cell_type": "code", "source": "# vienna_geo = r'BEZIRKSGRENZEOGD.json' # geojson file\nvienna_geo = location_data\n\n# create a plain map of Vienna\nvienna_map = folium.Map(location=[48.2012167,16.3725062], zoom_start=12)\n\n# add the data\nvienna_map.choropleth(\n    geo_data=location_data,\n    data=mean_per_district,\n    columns=['District', 'Size'],\n    key_on='feature.properties.name',\n    fill_color='YlOrRd', \n    fill_opacity=0.7, \n    line_opacity=0.2,\n    legend_name='Average apartment size for each district in Vienna'\n)\n\n# add markers to map\nfor lat, lng, postalcode, district in zip(district_coordinates['Latitude'], district_coordinates['Longitude'], district_coordinates['PostalCode'], district_coordinates['District']):\n    dist = postalcode[1:3]\n    label = '{}. {}'.format(dist, district)\n    label = folium.Popup(label, parse_html=True)\n    folium.Circle(\n        [lat, lng],\n        radius=100,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(vienna_map) \n\n# display map\nvienna_map", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# 5. Get Foursquare data"}, {"metadata": {}, "cell_type": "markdown", "source": "### Define Foursquare Credentials and Version"}, {"metadata": {}, "cell_type": "code", "source": "# @hidden_cell\nCLIENT_ID = '' # your Foursquare ID\nCLIENT_SECRET = '' # your Foursquare Secret\nVERSION = '20180605' # Foursquare API version", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Let's create a function to repeat the same process to all the districts in Vienna"}, {"metadata": {}, "cell_type": "code", "source": "def getNearbyVenues(names, latitudes, longitudes, radius=500, LIMIT=100):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['District', \n                  'District Latitude', \n                  'District Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "vienna_venues = getNearbyVenues(names=district_coordinates['District'],\n                                   latitudes=district_coordinates['Latitude'],\n                                   longitudes=district_coordinates['Longitude'],\n                                   radius=2000, LIMIT=100)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "vienna_venues.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print('{} venues are collected'.format(vienna_venues.shape[0]))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "vienna_venues.groupby('District').count()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Let's find out how many unique categories can be curated from all the returned venues"}, {"metadata": {}, "cell_type": "code", "source": "print('There are {} uniques categories.'.format(len(vienna_venues['Venue Category'].unique())))", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# 6. Analyze Each District"}, {"metadata": {}, "cell_type": "code", "source": "# one hot encoding\nvienna_onehot = pd.get_dummies(vienna_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# add neighborhood column back to dataframe\nvienna_onehot['District'] = vienna_venues['District'] \n\n# move neighborhood column to the first column\nfixed_columns = [vienna_onehot.columns[-1]] + list(vienna_onehot.columns[:-1])\nvienna_onehot = vienna_onehot[fixed_columns]\n\nvienna_onehot.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Next, let's group rows by district and by taking the mean of the frequency of occurrence of each category"}, {"metadata": {}, "cell_type": "code", "source": "vienna_grouped = vienna_onehot.groupby('District').mean().reset_index()\nvienna_grouped", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### First, let's write a function to sort the venues in descending order."}, {"metadata": {}, "cell_type": "code", "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Now let's create a new dataframe and display the top 10 venues for each district."}, {"metadata": {}, "cell_type": "code", "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['District']\nfor idx in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(idx+1, indicators[idx]))\n    except:\n        columns.append('{}th Most Common Venue'.format(idx+1))\n\n# create a new dataframe\ndistrict_venues_sorted = pd.DataFrame(columns=columns)\ndistrict_venues_sorted['District'] = vienna_grouped['District']\n\nfor idx in np.arange(vienna_grouped.shape[0]):\n    district_venues_sorted.iloc[idx, 1:] = return_most_common_venues(vienna_grouped.iloc[idx, :], num_top_venues)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "district_venues_sorted", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# 7. Cluster Districts"}, {"metadata": {}, "cell_type": "markdown", "source": "### Run k-means to cluster the districts into 2 clusters (in this case the best k is 2)"}, {"metadata": {}, "cell_type": "code", "source": "# set number of clusters\nkclusters = 2\n\nvienna_grouped_clustering = vienna_grouped.drop('District', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(vienna_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Let's create a new dataframe that includes the cluster as well as the price/m2 and the top 10 venues for each neighborhood."}, {"metadata": {}, "cell_type": "code", "source": "# add clustering labels\ndistrict_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\n# add price/m2 for each district\nvienna_merged = pd.merge(district_coordinates, mean_per_district[['District', 'Price/m2']])\n\n# add latitude/longitude for each district\nvienna_merged = vienna_merged.join(district_venues_sorted.set_index('District'), on='District')\n\nvienna_merged", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "vienna_merged['Cluster Labels'].value_counts()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Finally, let's visualize the resulting clusters"}, {"metadata": {}, "cell_type": "code", "source": "# create map\nmap_clusters = folium.Map(location=[48.2012167,16.3725062], zoom_start=12)\n\n# set colors\nrainbow = ['blue', 'red']\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(vienna_merged['Latitude'], vienna_merged['Longitude'], vienna_merged['District'], vienna_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster],\n        fill=True,\n        fill_color=rainbow[cluster],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# 8. Examine Clusters"}, {"metadata": {}, "cell_type": "markdown", "source": "### Cluster 1"}, {"metadata": {}, "cell_type": "code", "source": "cluster1 = vienna_merged.loc[vienna_merged['Cluster Labels'] == 0, vienna_merged.columns[[1] + list(range(5, vienna_merged.shape[1]))]]\ncluster1", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Cluster 2"}, {"metadata": {}, "cell_type": "code", "source": "cluster2 = vienna_merged.loc[vienna_merged['Cluster Labels'] == 1, vienna_merged.columns[[1] + list(range(5, vienna_merged.shape[1]))]]\ncluster2", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "#### By analyzing the clusters we can see that cluster 1 is more residential since it contains lots of parks and supermarkets while cluster 2 is more commercial / touristic and contains many hotels and restaurants"}, {"metadata": {}, "cell_type": "markdown", "source": "# 9. Final Visualization"}, {"metadata": {}, "cell_type": "markdown", "source": "With all the gathered data we can now create a choropleth map displaying the average price/m2 for each district as well as display information about the area type and top 10 locations for each district on the marker labels. With this map, one could determine for example that the 1st district is the most expensive district to live in, however by clustering we determined that there are several more similar districts where the price/m2 is significantly lower. Therefore, if someone wants to rent an apartment but cannot afford to live in the 1st district, they could look for apartments in the 12th or 15th district which is similar in venues but has much lower price for renting apartments."}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}